This serves as a list of requirements for a personal dropbox clone.

1) No concept of a server or client.
    Each actor in this system should be the same. No 'server' should exist
2) An arbitrary number of clients can receive changes from any given node.
3) Multiple folders on a single machine should be kept track of independently
        Each can have multiple differing clients
        Each can be synchronized independently.
        Each can be configured independently.
        Folder location should be local to the machine.
4) Nodes should be able to instantly get changes from other nodes.
        Can we do this without pushing changes?
        How do we prevent a cyclical push? do we care?
5) Offline nodes need to be able to sync the backlog of changes when they come
    online.
6) Expired data should be pruned.
        Expired could mean after X amount of time, or X changes, or X size...
7) Mutually edited files should be caught and reported, or at least recoverable
    with no interruption in service.
8) Because this is to work on multiple machines, we should be ownership, group,
    etc. agnostic.
9) Because forcing people to install rdiff-backup sucks, backing up should use
    a more NIH-like solution, where we split files up with a rolling checksum,
    then backup the files using their fragmented chunks. See bup, librsync
    for more details. [bup suffers from an inability to prune, which is 90%
    of why I wrote this]

NTH:
    All files encrypted to access.
    Full change-for-change history of all files everywhere, even across rebases
        and other mucking with our history locally.
    git-like command structure for funtime scriptableness.
        (sync [opts] command [opts] -> sync-command [opts])
How does this look to us?
Subsystems:
    inotify for listening for file changes.
    rsync for synchronization between nodes.
		rsync using --delay-updates and --partial-dir to make updates atomic
		use --exclude .yafs to exclude our dropbox thing.
		use --delay-updates to make updates atomic.
		use --delete-delay to delete files from the dest
			this could cause data loss if they've got a pending update, but fu.
		use -stlurp to only update out-of-date ones.
		Note that deletions are fucking dangerous as shit this way (we should have history, so meh).
		Also, we could do something FUN and fucking only go one way and shit.

Command structure
	yafs init -- create a new yafs directory here.
		Also register something with crontab somehow. (in user crontab?)
		yafs directory structure should be something like:
			.yafs/backup/ -- rdiff backups
			.yafs/config -- config information
			.yafs/remotes -- remote server configuration
			.yafs/tmp/sync -- rsync tempdir
	yafs remote -- Keep track of remote servers
	yafs push -- push changes to remotes
	yafs pull -- pull changes from remotes
	yafs sync -- push & pull from remotes
	yafs clone -- Init, add remote & pull
	yafs help -- print some fucking message
	yafs history -- List all past versions of this file.
	yafs restore -- restore a version of the file.

	to be added:
	yafs increment -- When a more formal backup system is in place
	yafs daemon -- watch directories for changes & increment immediately
	yafs ping -- check if the remote hosts are online

